{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import string\n",
    "import nltk\n",
    "import warnings \n",
    "st = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:\\\\Users\\\\shreyas.raghavan\\\\Desktop\\\\NLP\\\\ASSN-W4\\\\Assignment sarcasm train data.csv')\n",
    "test = pd.read_csv('C:\\\\Users\\\\shreyas.raghavan\\\\Desktop\\\\NLP\\\\ASSN-W4\\\\Assignment sarcasm test data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['label'] =np.where(train['label']=='sarcastic',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T000452360</td>\n",
       "      <td>@alleygirl2409 until i\\'m and all the old men ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T000452361</td>\n",
       "      <td>b\"@sarinas it had been chanted peacefully you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T000452365</td>\n",
       "      <td>b'Wow I really forgot how much I love the traf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T000452367</td>\n",
       "      <td>b'Love having no voice $$SAR$$'</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T000452368</td>\n",
       "      <td>b'Apparently i have to sacrifice a goat and do...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                              tweet  label\n",
       "0  T000452360  @alleygirl2409 until i\\'m and all the old men ...      1\n",
       "1  T000452361  b\"@sarinas it had been chanted peacefully you ...      1\n",
       "2  T000452365  b'Wow I really forgot how much I love the traf...      1\n",
       "3  T000452367                    b'Love having no voice $$SAR$$'      1\n",
       "4  T000452368  b'Apparently i have to sacrifice a goat and do...      1"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "comb = train.append(test, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "    return input_txt   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing\n",
    "comb['clean'] = np.vectorize(remove_pattern)(comb['tweet'], \"@[\\w]*\")\n",
    "comb['clean'] = comb['clean'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "comb['clean'] = comb['clean'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [until, and, all, the, old, men, will, finally...\n",
       "1    [it, had, been, chanted, peacefully, you, can,...\n",
       "2    [Wow, really, forgot, how, much, love, the, tr...\n",
       "3                       [Love, having, no, voice, SAR]\n",
       "4    [Apparently, have, to, sacrifice, goat, and, d...\n",
       "Name: clean, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tweet = comb['clean'].apply(lambda x: x.split())\n",
    "tokenized_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [until, and, all, the, old, men, will, final, ...\n",
       "1    [it, had, been, chant, peac, you, can, deni, #...\n",
       "2    [wow, realli, forgot, how, much, love, the, tr...\n",
       "3                          [love, have, no, voic, sar]\n",
       "4    [appar, have, to, sacrific, goat, and, do, rai...\n",
       "Name: clean, dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\n",
    "tokenized_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tokenized_tweet)):\n",
    "    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
    "comb['clean'] = tokenized_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T000452360</td>\n",
       "      <td>1.0</td>\n",
       "      <td>@alleygirl2409 until i\\'m and all the old men ...</td>\n",
       "      <td>until and all the old men will final date me #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T000452361</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b\"@sarinas it had been chanted peacefully you ...</td>\n",
       "      <td>it had been chant peac you can deni #hypocrisy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T000452365</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'Wow I really forgot how much I love the traf...</td>\n",
       "      <td>wow realli forgot how much love the traffic scene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T000452367</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'Love having no voice $$SAR$$'</td>\n",
       "      <td>love have no voic sar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T000452368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'Apparently i have to sacrifice a goat and do...</td>\n",
       "      <td>appar have to sacrific goat and do rain danc t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  label                                              tweet  \\\n",
       "0  T000452360    1.0  @alleygirl2409 until i\\'m and all the old men ...   \n",
       "1  T000452361    1.0  b\"@sarinas it had been chanted peacefully you ...   \n",
       "2  T000452365    1.0  b'Wow I really forgot how much I love the traf...   \n",
       "3  T000452367    1.0                    b'Love having no voice $$SAR$$'   \n",
       "4  T000452368    1.0  b'Apparently i have to sacrifice a goat and do...   \n",
       "\n",
       "                                               clean  \n",
       "0  until and all the old men will final date me #...  \n",
       "1  it had been chant peac you can deni #hypocrisy...  \n",
       "2  wow realli forgot how much love the traffic scene  \n",
       "3                              love have no voic sar  \n",
       "4  appar have to sacrific goat and do rain danc t...  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000)\n",
    "# TF-IDF feature matrix\n",
    "tfidf = tfidf_vectorizer.fit_transform(comb['clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ##VALIDATING THE DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "train_tfidf = tfidf[:45529,:]\n",
    "test_tfidf = tfidf[45530:,:]\n",
    "\n",
    "# splitting data into training and validation set\n",
    "xtrain_tfidf, xvalid_tfidf, ytrain, yvalid = train_test_split(train_tfidf, train['label'], random_state=42, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "# Gini-model\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#X, y = make_hastie_10_2(random_state=0)\n",
    "#X_train, X_test = X[:2000], X[2000:]\n",
    "#y_train, y_test = y[:2000], y[2000:]\n",
    "\n",
    "\n",
    "clf= GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0).fit(xtrain_tfidf, ytrain)\n",
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "#bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    " #                        algorithm=\"SAMME\",\n",
    "  #                       n_estimators=200)\n",
    "\n",
    "#bdt.fit(xtrain_tfidf, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pred=predict=clf.predict_proba(xvalid_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_int = gb_pred[:,1] >= 0.5000000\n",
    "prediction_int = prediction_int.astype(np.int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8411895360315893"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "train_tfidf = tfidf[:45529,:]\n",
    "test_tfidf = tfidf[45530:,:]\n",
    "\n",
    "xtrain_tfidf = tfidf[:45529,:]\n",
    "xvalid_tfidf = tfidf[45529:,:]\n",
    "ytrain= train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "# Gini-model\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#X, y = make_hastie_10_2(random_state=0)\n",
    "#X_train, X_test = X[:2000], X[2000:]\n",
    "#y_train, y_test = y[:2000], y[2000:]\n",
    "\n",
    "\n",
    "clf= GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0).fit(xtrain_tfidf, ytrain)\n",
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "#bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         #algorithm=\"SAMME\",\n",
    "                         #n_estimators=200)\n",
    "\n",
    "#bdt.fit(xtrain_tfidf, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_pred=clf.predict_proba(xvalid_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45769"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = gb_pred[:,1] >= 0.5000000\n",
    "prediction_int = prediction_int.astype(np.int)\n",
    "len(prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45769, 2)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['label']=prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T000452358</td>\n",
       "      <td>b'oh yea that makes sense '</td>\n",
       "      <td>sarcastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T000452359</td>\n",
       "      <td>Estas enfermedad a un cargo poltico tu como pb...</td>\n",
       "      <td>non-sarcastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T000452362</td>\n",
       "      <td>b\"there's nothing like being on vacation and h...</td>\n",
       "      <td>sarcastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T000452363</td>\n",
       "      <td>People who are sarcastic tend to be better pro...</td>\n",
       "      <td>sarcastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T000452364</td>\n",
       "      <td>b'May I block you too RT But what if he or she...</td>\n",
       "      <td>non-sarcastic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                              tweet  \\\n",
       "0  T000452358                        b'oh yea that makes sense '   \n",
       "1  T000452359  Estas enfermedad a un cargo poltico tu como pb...   \n",
       "2  T000452362  b\"there's nothing like being on vacation and h...   \n",
       "3  T000452363  People who are sarcastic tend to be better pro...   \n",
       "4  T000452364  b'May I block you too RT But what if he or she...   \n",
       "\n",
       "           label  \n",
       "0      sarcastic  \n",
       "1  non-sarcastic  \n",
       "2      sarcastic  \n",
       "3      sarcastic  \n",
       "4  non-sarcastic  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['label'] =np.where(test['label']==1,'sarcastic','non-sarcastic')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_csv('C:\\\\Users\\\\shreyas.raghavan\\\\Desktop\\\\NLP\\\\ASSN-W4\\\\Assignment_sarcasm_scored_data_shreyas_0487.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
